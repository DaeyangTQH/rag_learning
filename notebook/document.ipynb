{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a56a98",
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "id": "a3eca2a3",
   "metadata": {},
   "source": [
    "###Document structure\n",
    "from langchain_core.documents import Document\n",
    "from pydantic_core.core_schema import none_schema\n",
    "from pymupdf.mupdf import pdf_document"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9f726d431c51f83",
   "metadata": {},
   "source": [
    "doc = Document(\n",
    "    page_content=\"This is the main content I'm using to create RAG\",\n",
    "    metadata={\n",
    "        \"source\":\"example.txt\",\n",
    "        \"pages\": 1,\n",
    "        \"author\": \"hai tran\",\n",
    "        \"date_created\": \"17-12-2025\"\n",
    "    }\n",
    ")\n",
    "doc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ec2156af8bb9863",
   "metadata": {},
   "source": [
    "## Create a simple text file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\", exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5379d7a47a2658ba",
   "metadata": {},
   "source": [
    "sample_text = {\n",
    "    \"../data/text_files/python_intro.txt\": \"\"\"\n",
    "Python is a high-level, general-purpose programming language created by Guido van Rossum\n",
    "and first released in 1991.\n",
    "\n",
    "Python is known for its simple and readable syntax, which makes it a popular choice\n",
    "for beginners as well as experienced developers.\n",
    "\n",
    "The language supports multiple programming paradigms, including procedural,\n",
    "object-oriented, and functional programming. Python is widely used in web development,\n",
    "data science, artificial intelligence, automation, and scientific computing.\n",
    "\"\"\",\n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"\n",
    "Machine learning is a field of computer science that focuses on building systems\n",
    "that can learn from data and improve their performance over time without being\n",
    "explicitly programmed.\n",
    "\n",
    "It is a core subfield of artificial intelligence and is commonly used in applications\n",
    "such as recommendation systems, image recognition, speech recognition, and fraud detection.\n",
    "\n",
    "Machine learning algorithms are typically categorized into supervised learning,\n",
    "unsupervised learning, and reinforcement learning.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "for filepath, content in sample_text.items(): # items trả về key-value\n",
    "    with open(filepath, \"w\") as f: # with cung cấp các helper method tương đưuong với việc gọi hàm __enter__ và __exit__ giúp đơn giản hóa\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample text files created successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7bfef8c4",
   "metadata": {},
   "source": [
    "### Textloader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "document = loader.load()\n",
    "print(document)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## Load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", #Pattern to match files\n",
    "    loader_cls=TextLoader, #Loader class to use for each file\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "document = dir_loader.load()\n",
    "document"
   ],
   "id": "a98386266628b7d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "## Load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdfs\",\n",
    "    glob=\"**/*.pdf\", #Pattern to match files\n",
    "    loader_cls=PyMuPDFLoader, #Loader class to use for each file\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "pdf_document = dir_loader.load()\n",
    "pdf_document"
   ],
   "id": "28bb4203cb9501a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:01:32.415848Z",
     "start_time": "2025-12-18T15:01:32.411294Z"
    }
   },
   "cell_type": "markdown",
   "source": "### Embedding Manager",
   "id": "bf2da65b1c847425"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import chromadb\n",
    "import uuid\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os"
   ],
   "id": "3c170a4d7fc75e00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embeddings generation using SentenceTransformer.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the EmbeddingManager with the specified model name.\n",
    "\n",
    "        Args:\n",
    "              model_name (str): Hugging Face model name to use for embedding generation. Defaults to \"all-MiniLM-L6-v2.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model.\"\"\"\n",
    "        try:\n",
    "            print(f'loading embedding model: {self.model_name}')\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f'embedding model loaded successfully. Embedding dimension: {self.get_embedding_dimension()}')\n",
    "        except Exception as e:\n",
    "            print(f\"Erorr loading model {self.model_name}: {e}\")\n",
    "            raise  # Giống với throw exception trong Java\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts.\n",
    "\n",
    "        :param texts: List of text strings to embed\n",
    "        :return: a numpy array of embeddings with shapes (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.model:  # Nếu chưa tồn tại object\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "\n",
    "        print(f\"Generating embedding model for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Embeddings generated successfully. Shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "    def get_embedding_dimension(self) -> int:\n",
    "        \"\"\"Get the dimension of the embedding model\"\"\"\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "\n",
    "# Initialize the embedding manager\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ],
   "id": "dc23433ea3acae22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Vector Store",
   "id": "6c39962d7bc2e1bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:02:01.742018Z",
     "start_time": "2025-12-18T15:02:01.552851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Vector Store Database\n",
    "class VectorStore:\n",
    "    \"\"\"Manages documents embeddings in a ChromaDB vector store\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "\n",
    "        :param collection_name: Name of the ChromaDB collection to use.\n",
    "        :param persist_directory: Directory to persist to vector store\n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize the ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent chromadb client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create a collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                # Giống với table trong db - CREATE TABLE IF NOT EXISTS\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF documents embeddings for RAG\"}\n",
    "            )\n",
    "\n",
    "            print(f\"Vector store initialized successfully. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB client: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add lists of langchain documents and embeddings to the vector store\n",
    "\n",
    "        :param documents: List of langchain documents\n",
    "        :param embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents and embeddings must be equal\")\n",
    "\n",
    "        # Prepare data for db\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(\n",
    "                zip(documents, embeddings)):  # zip để đóng các cặp doc-emb tươgn ứng lại với nhau\n",
    "            #Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            #Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            #Embedding\n",
    "            embeddings_list.append(embedding)\n",
    "\n",
    "        #Add to a collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Documents added to collection: {self.collection_name}\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to collection: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "vector_store = VectorStore()\n",
    "vector_store"
   ],
   "id": "1b97614ef2754d2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m### Vector Store Database\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43;01mVectorStore\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[38;5;250;43m    \u001B[39;49m\u001B[33;43;03m\"\"\"Manages documents embeddings in a ChromaDB vector store\"\"\"\u001B[39;49;00m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[38;5;250;43m \u001B[39;49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpdf_documents\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m../data/vector_store\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 39\u001B[39m, in \u001B[36mVectorStore\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     36\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mError initializing ChromaDB client: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     37\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34madd_documents\u001B[39m(\u001B[38;5;28mself\u001B[39m, documents: \u001B[43mList\u001B[49m[Any], embeddings: np.ndarray):\n\u001B[32m     40\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     41\u001B[39m \u001B[33;03m    Add lists of langchain documents and embeddings to the vector store\u001B[39;00m\n\u001B[32m     42\u001B[39m \n\u001B[32m     43\u001B[39m \u001B[33;03m    :param documents: List of langchain documents\u001B[39;00m\n\u001B[32m     44\u001B[39m \u001B[33;03m    :param embeddings: Corresponding embeddings for the documents\u001B[39;00m\n\u001B[32m     45\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m     47\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(documents) != \u001B[38;5;28mlen\u001B[39m(embeddings):\n",
      "\u001B[31mNameError\u001B[39m: name 'List' is not defined"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAG)",
   "language": "python",
   "name": "rag-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
